{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4ae9f1",
   "metadata": {},
   "source": [
    "# Machine Learning Projekt - Gruppe 9\n",
    "## Projekt: _Electric Motor Temperature Estimation_\n",
    "### SS2025\n",
    "\n",
    "Gruppenmitglieder: André Korten, Fynn Buhl, Kilian Feil, Lukas Quast, Nic Tusch, Tobias Weismantel\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d10acb",
   "metadata": {},
   "source": [
    "## Aufgabenstellung:\n",
    "\n",
    "Aufgabe des Projekts ist es, auf Grundlage des vorliegenden Datensatzes die Temperatur des Permanentmagneten eines datas vorherzusagen.\n",
    "Zur Umsetzung dieser Regressionsaufgabe werden zwei vorgegebene Verfahren eingesetzt: Random Forest sowie ANN. Zusätzlich wird ein drittes, selbst gewähltes Verfahren zur Modellierung und zum Vergleich herangezogen.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98d8c5",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Problemdefinition und Kontext\n",
    "\n",
    "#### Zielsetzung (Objective)\n",
    "\n",
    "Ziel des Projekts ist es, auf Basis der Messwerte von Spannung (`u_d`, `u_q`) und Strom (`i_d`, `i_q`) in dq-Koordinaten sowie weiterer verfügbarer Sensordaten (z. B. Drehmoment und Drehzahl) die Temperatur des Permanentmagneten (`pm`) vorherzusagen. Auf die Verwendung von Temperaturmesswerten benachbarter Motorbauteile soll dabei nach Möglichkeit verzichtet werden, da diese nicht in jeder Anwendung zwangsläufig zur Verfügung stehen. Ein präzises Temperaturmodell soll die frühzeitige Erkennung potenziell schädlicher Überhitzung ermöglichen, bevor reale Schäden auftreten, und ist damit ein wichtiger Baustein für eine vorausschauende Wartung und den Schutz des Motors.\n",
    "\n",
    "**Business Objective:** Vermeidung von Leistungseinbussen Motorschäden durch rechtzeitiges Erkennen kritischer Temperaturen.\n",
    "\n",
    "Die Literatur weist darauf hin, dass Abweichungen von etwa 10 % oberhalb etablierter Temperaturgrenzen zu gefährlichen Zuständen, Motorschäden oder erheblichen Leistungsminderungen führen können. Studien zeigen, dass präzise Temperaturprognosen mit einer Abweichung von weniger als 5 °C notwendig sind, um frühzeitig thermische Überlastungen zu erkennen und eine zuverlässige Lebensdauer der Permanentmagneten zu gewährleisten. Gängige Thermokoppler mit Industrieanwendung weisen eine Mess-Toleranz von ±2°C auf.\n",
    "\n",
    "Daher wird der **Zielbereich für die zu untersuchenden ML-Modelle auf ±2 °C festgelegt**.\n",
    "\n",
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "#### Leistungsbewertung (Performance Criteria)\n",
    "\n",
    "Zur Bewertung der Modellleistung wird die gebräuchliche Metrik für Regressionsaufgaben verwendet:\n",
    "\n",
    "- **Root Mean Square Error (RMSE):** Betonung größerer Fehler, empfindlich gegenüber Ausreißern, gut geeignet, wenn starke Abweichungen kritisch sind.\n",
    "- **Mean Absolute Error (MAE):** Durchschnittlicher Fehler, robuster gegenüber Ausreißern, liefert eine intuitive Interpretation („um wie viel Grad liege ich im Mittel daneben?“).\n",
    "\n",
    "**Ziel:** Minimierung beider Werte, wobei RMSE als Hauptoptimierungsmetrik dient.\n",
    "\n",
    "\n",
    "\n",
    "#### Lösungsansatz ohne Machine Learning\n",
    "\n",
    "Bisher wird die Temperatur des Permanentmagneten mit Thermoelementen direkt am Prüfstand gemessen. In einem rein regelbasierten System könnten Grenzwerte überwacht und bei Überschreitung automatisch die Leistung gedrosselt werden. Alternativ wäre denkbar, einfache physikalische Modelle (z. B. basierend auf Energieverlusten durch Stromfluss, Wärmeübertragung und Umgebungstemperatur) zu verwenden, um Temperaturentwicklungen zu schätzen. Diese Modelle wären jedoch stark vereinfacht und schwer auf unterschiedliche Lastprofile übertragbar.\n",
    "\n",
    "\n",
    "\n",
    "#### Annahmen (Assumtions)\n",
    "\n",
    "- Supervised Learning: Es liegen gelabelte Trainingsdaten des Zielwerts `pm` vor.\n",
    "- Offline / Batch Learning: Das Modell wird auf einem statischen Datensatz trainiert, da alle Daten in den Speicher passen und kein kontinuirlicher Datenstrom erwartet wird\n",
    "- Univariate Regression: Nur ein Zielwert (`pm`) wird vorhergesagt.\n",
    "- Multiple Regressions Aufgabe: Da mehrer Eingangsgrößen zur Vorhersage verwendet werden.\n",
    "- Keine defekten Motorzustände im Datensatz vorhanden.\n",
    "- Alle Daten sind numerisch, keine kategorialen Features.\n",
    "- Die `profile_id` stellt unterschiedliche Testzyklen dar.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages for the whole project\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pprint \n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639a80b",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Verwendeter Datensatz\n",
    "\n",
    "#### Kontext\n",
    "\n",
    "Der Datensatz enthält Sensormessdaten eines Permanentmagnet-Synchronmotors (PMSM), der auf einem Prüfstand betrieben wurde. Es handelt sich um einen Prototyp eines deutschen OEMs. Die Messungen wurden durch die Universität Paderborn durchgeführt.\n",
    "\n",
    "#### Struktur\n",
    "\n",
    "- **Samplingrate:** 2 Hz  \n",
    "- **Messdauer:** 1 bis 6 Stunden je Session  \n",
    "- **Sessions:** Unterscheidbar durch `profile_id`  \n",
    "- **Lastprofil:** Zufällige Lastwechsel (random walk) zur realitätsnahen Simulation dynamischer Betriebszustände\n",
    "\n",
    "#### Feature-Beschreibung\n",
    "\n",
    "- **u_d, u_q:** Spannungen in d/q-Koordinaten (in V)  \n",
    "- **i_d, i_q:** Ströme in d/q-Koordinaten (in A)  \n",
    "- **motor_speed:** Motordrehzahl (in rpm)  \n",
    "- **torque:** Drehmoment (in Nm)  \n",
    "- **coolant, ambient, stator_winding, stator_tooth, stator_yoke:** Temperaturmessungen an verschiedenen Stellen (in °C)\n",
    "- **pm:** Temperatur des Permanentmagneten (Zielgröße) (in °C)\n",
    "\n",
    "Die d/q-Komponenten resultieren aus einem geregelten Antriebssystem, das Drehzahl und Moment möglichst genau an Referenzwerte anpasst.\n",
    "\n",
    "Quelle:\n",
    "[Electric Motor Temperature Dataset – Kaggle](https://www.kaggle.com/datasets/wkirgsn/electric-motor-temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04989a54",
   "metadata": {},
   "source": [
    "#### Daten einlesen\n",
    "\n",
    "Um den Datensatz effizient und flexibel laden zu können, wird eine eigene Ladefunktion definiert. Pfad und Dateiname können dabei unkompliziert angepasst werden.\n",
    "Standardmäßig wird angenommen, dass die Datei eine Kopfzeile (Header) enthält. Dies trifft auch für den verwendetet Datensatz zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where the data file is stored\n",
    "DATA_PATH = \"./\"\n",
    "CSV_FILE = \"measures_v2.csv\"\n",
    "\n",
    "# Function to load motor data from a CSV file an retur an pandas DataFrame\n",
    "def load_motor_data(data_path=DATA_PATH, filename=CSV_FILE):\n",
    "    csv_path = os.path.join(data_path, filename) #CSV file has a header row -> Default: Assumes that the first row is the header\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Load the motor dataset using the defined function\n",
    "data = load_motor_data(DATA_PATH, CSV_FILE)\n",
    "\n",
    "# Display information about the loaded DataFrame, to briefly validate a succseful import\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbd2d6",
   "metadata": {},
   "source": [
    "#### Erster Überblick über den Datensatz\n",
    "\n",
    "Der Befehl `data.info()` gibt einen kompakten Überblick über den geladenen DataFrame. Damit lassen sich grundlegende Eigenschaften des Datensatzes überprüfen:\n",
    "\n",
    "- **Anzahl der Einträge:**  \n",
    "  `RangeIndex: 1330816 entries, 0 to 1330815`  \n",
    "  → Der Datensatz enthält ca. **1,33 Millionen Zeilen**, ist also recht umfamgreich.\n",
    "\n",
    "- **Spaltenanzahl und Datentypen:**  \n",
    "  `total 13 columns`, davon `12 x float64`, `1 x int64`  \n",
    "  → Es liegen ausschließlich **numerische Daten** vor, keine Strings oder kategorischen Variablen  – ein Preprocessing-Schritt zum Encoden ist nicht nötig.\n",
    "\n",
    "- **Fehlende Werte:**  \n",
    "  `Non-Null Count` ist in jeder Spalte gleich der Gesamtanzahl der Zeilen (1330816)  \n",
    "  → **Es gibt keine fehlenden Werte** – ein Preprocessing-Schritt zum Auffüllen (`fillna`) ist nicht nötig.\n",
    "\n",
    "- **Speicherauslastung:**  \n",
    "  `memory usage: 132.0 MB`  \n",
    "  → Die Datenmenge ist überschaubar und kann im RAM verarbeitet werden (Batch Learning möglich).\n",
    "\n",
    "\n",
    "Um einen ersten Endruck über die Sturktur des datensatzes zu bekommen werden mit `data.head()` die ersten Zeilen des Datensatztes und mit `data.describe()` eine statistiche Zusammenfassung ausgegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c06724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots histograms for all features.\n",
    "# Useful for detecting outliers, distribution shapes, and scale differences.\n",
    "data.hist(bins=80, figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69536f9d",
   "metadata": {},
   "source": [
    "**Zentrale Erkenntnisse:**\n",
    "\n",
    "\n",
    "- **Größenordnung der Messwerte & Einheiten passen:**  \n",
    "  Alle Messwerte befinden sich in sinnvollen physikalischen Größenbereich.\n",
    "\n",
    "- **Histogramme zeigen für die meisten Features eine annähernd Normalverteilung.**\n",
    "\n",
    "- **Skalierung der Features variiert stark:**\n",
    "  - `motor_speed`: Ø ≈ 2200, max ≈ 6000\n",
    "  - `coolant`, `ambient`, `pm`: typischer Temperaturbereich 10–110 °C\n",
    "  - `i_q`: zwischen -293 und +301 → hohe Dynamik in der Stromregelung\n",
    "  - `u_d`: reicht von -131 bis +131 → symmetrische Verteilung\n",
    "  → **Feature Scaling** ist notwendig für viele ML-Modelle.\n",
    "\n",
    "- **Negative Werte bei `torque`, `i_q`, `i_d`, `u_d`, `u_q`.**\n",
    "\n",
    "- **`profile_id`:**\n",
    "  - Wertebereich: 2 bis 81\n",
    "  - → nicht alle IDs sind vergeben.\n",
    "\n",
    "- **Zielvariable `pm` (Permanentmagnet-Temperatur):**\n",
    "  - Mittelwert: 58,5 °C\n",
    "  - Minimum: 20,9 °C\n",
    "  - Maximum: 113,6 °C\n",
    "  → kein extremer Ausreißerbereich.\n",
    "\n",
    "- **Hohe Anzahl 0-naher Werte**:\n",
    "  - Besonders bei den Features `motor_speed`, `torque`, `i_q`, `i_d`, `u_d` und `u_q` fällt die hohe Anzahl 0-naher Werte auf. Später soll daher überprüft werden ob dieses ungleichgewicht der Messwertverteilung einen negativen Einfluss uaf die ML-Modelle hat und entsprechende Zeilen ggf. aus dem Datensatz entfernt werden sollten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366066f",
   "metadata": {},
   "source": [
    "#### Trainings- und Testset erstellen\n",
    "\n",
    "Um sicherzustellen, dass alle Messsessions (`profile_id`) im Trainings- und Testdatensatz proportional vertreten sind, wird ein **stratifiziertes Sampling** durchgeführt. Dadurch bleibt die Verteilung der Messsessions in beiden Datensätzen erhalten, was Über- oder Unterrepräsentation einzelner Sessions vermeiden und die Generalisierbarkeit des Modells verbessern soll.\n",
    "\n",
    "Da der Datensatz sehr groß ist (~1,3 Mio. Einträge), reicht ein Testset mit **1% der Daten** aus, um valide Modellevaluationen durchzuführen (vgl. Vorlesung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a stratified test set from all sessions (multiple measurements can be distinguished from each other by column profile_id)\n",
    "print(data[\"profile_id\"].describe())\n",
    "\n",
    "\n",
    "# Testsetsize = 1%, due to more then 100000 Datapoints\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.01, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"profile_id\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "\n",
    "\n",
    "# Verify that the stratified test set (orange) preserves the same distribution shape as the full dataset (blue), \n",
    "# but with ~99% of the sample size (lower bars with identical relative frequencies).   \n",
    "data[\"profile_id\"].hist()    \n",
    "strat_train_set[\"profile_id\"].hist()\n",
    "plt.title(f\"Verteilung der profile_id in Training- und Testset\")\n",
    "plt.xlabel(\"profile_id\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f777ff90",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Datenexploration\n",
    "\n",
    "#### Verteilung der Zielvgröße `pm` - Permanetmagnet-Temeperatur\n",
    "\n",
    "Die Verteilung der Zielgröße `pm` wird als Histogramm mit Dichtekurve dargestellt.  \n",
    "Dies hilft, mögliche Schieflagen, Ausreißer oder Auffälligkeiten zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5671f10-3fca-4000-b16f-13f632632b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the 'pm' column from the 'exploration_set' DataFrame.\n",
    "# Shows the distributions, skewness for target variable (pm).\n",
    "# The KDE provides a smoothed representation of the data's distribution.\n",
    "sns.histplot(strat_train_set['pm'], kde=True)\n",
    "plt.title(f\"Verteilung der PM-Temp. im Explorationset\")\n",
    "plt.xlabel(\"PM-Temp.\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show statistical data for target value\n",
    "strat_train_set['pm'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc241",
   "metadata": {},
   "source": [
    "Der Großteil der Messwerte zeigt, dass der Magnet am häufigsten in einem Bereich von **60 bis 70 °C** betrieben wird, was den typischen Hauptbetriebszustand widerspiegelt. Eine weitere Konzentration der Messungen liegt bei **25 bis 35 °C** und **45 bis 55 °C**, was auf Phasen mit geringerer Last oder Leerlauf hindeutet.\n",
    "\n",
    "Die Durchschnittstemperatur beträgt 58,51 °C, mit einer Standardabweichung von 19 °C wird die Streuung der Temperaturen als gering/moderat eingestuft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b34d8",
   "metadata": {},
   "source": [
    "#### Erstellung eines kompakten Explorations-Datensatzes\n",
    "\n",
    "Für die weitere explorative Datenanalyse wird ein kleiner, aber repräsentativer Ausschnitt aus dem Trainingsdatensatz benötigt. Ziel ist es, einfache Analysen, Visualisierungen und Vorverarbeitungsschritte schnell und ressourcenschonend durchzuführen – ohne direkt auf den vollständigen Trainings-Datensatz zugreifen zu müssen.\n",
    "\n",
    "Dazu werde mittels **stratifiziertem Sampling** 20% des Trainingsdatensatzes ausgewählt, wobei die Verteilung der unterschiedlichen Messsessions (`profile_id`) beibehalten wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the training set for exploration\n",
    "data_exploration = strat_train_set.copy()\n",
    "\n",
    "# sample the exploration_set down to ~20% of the original trainingset for easy and fast exploration\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for _, exploration_index in split.split(data_exploration, data_exploration[\"profile_id\"]):\n",
    "    exploration_set = data_exploration.iloc[exploration_index].copy()\n",
    "    \n",
    "\n",
    "exploration_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5e13c",
   "metadata": {},
   "source": [
    "#### Korrelationsanalyse\n",
    "\n",
    "Mit der Korrelationsmatrix wird untersucht, wie stark die einzelnen Features mit der Zielgröße `pm` (Permanentmagnet-Temperatur) zusammenhängen.  \n",
    "Das Sortieren der Korrelationen nach `pm` zeigt, welche Messgrößen den größten Einfluss auf die Temperatur haben und damit für das Modell besonders relevant sein könnten. Dies wird unten zusätzlich grafisch als Heatmap dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39be2c-d0ad-4ab5-b887-79a9cdf8f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcutale correlation matrix\n",
    "corr_matrix = exploration_set.corr()\n",
    "\n",
    "# look at how much each attribute correlates with the pm temp:\n",
    "corr_matrix[\"pm\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix as a heatmap\n",
    "# Annotate cells with correlation values, formatted to two decimals\n",
    "# Use 'coolwarm' color map to highlight positive and negative correlations\n",
    "# Set figure size and enforce square cells for better readability\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62330e7",
   "metadata": {},
   "source": [
    "Die Analyse zeigt, dass die Temperaturen an verschiedenen Motorteilen sehr stark mit der Permanentmagnet-Temperatur (`pm`) korrelieren:  \n",
    "- Besonders hohe positive Korrelationen haben `stator_tooth` (0,83), `stator_winding` (0,80) und `stator_yoke` (0,76).  \n",
    "- Die Umgebungs- (`ambient`, 0,51) und Kühlwassertemperatur (`coolant`, 0,47) zeigen moderate positive Zusammenhänge.  \n",
    "\n",
    "Auf die Verwendung von Temperaturmesswerten benachbarter Motorbauteile soll jedoch verzichtet werden, da diese nicht in jeder Anwendung zwangsläufig zur Verfügung stehen.\n",
    "\n",
    "- die Motordrehzahl `motor_speed` korrelieren (0,46) ebenfalls positiv, wenn auch schwächer.  \n",
    "\n",
    "Spannungen und Ströme weisen geringe bis mäßige negative Korrelationen auf, z. B. `i_d` (-0,43), was auf komplexere Einflüsse oder Gegenläufigkeiten hindeutet.\n",
    "\n",
    "Die Korrelation von 0,39 zwischen `pm` und `profile_id` zeigt zwar einen gewissen Zusammenhang, aber `profile_id` ist eigentlich nur ein Identifikator für verschiedene Messsessions. Dieser Wert (0,39) spiegelt also keine physikalische Beziehung wider, sondern eher, dass unterschiedliche Messungen (Sessions) unterschiedliche Temperaturniveaus haben können. Für die Modellierung ist `profile_id` daher eher kein sinnvoller Prädiktor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9dc610",
   "metadata": {},
   "source": [
    "Die Motordrehzahl (`motor_speed`) ist eine zentrale Betriebsgröße, die mechanische Belastung und thermische Zustände beeinflusst (siehe Korrelation zu `pm`).  \n",
    "Die Analyse der Korrelationen mit `motor_speed` identifiziert relevante Einflussgrößen und unterstützt die Auswahl signifikanter Features für die Modellierung.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at how much each attribute correlates with the motor_speed:\n",
    "corr_matrix[\"motor_speed\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa2d29",
   "metadata": {},
   "source": [
    "Die Motordrehzahl (`motor_speed`) zeigt starke positive Korrelationen mit den elektrischen Größen `u_q` (0,68) und eine starke negative Korrelation mit `i_d` (-0,70).  \n",
    "\n",
    "Auch die Permanentmagnet-Temperatur (`pm`) sowie Temperaturen an Wicklung (`stator_winding`) und Zahn (`stator_tooth`) korrelieren (wie erwartet) moderat positiv mit der Drehzahl.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db07148",
   "metadata": {},
   "source": [
    "#### Daten Visualisierung\n",
    "\n",
    "Der folgende Pairplot visualisiert die paarweisen Zusammenhänge zwischen den zentralen physikalischen Merkmalen des Motors: `u_q`, `i_q`, `motor_speed`, `torque` und `pm`.  \n",
    "Diese Merkmale wurden ausgewählt, da sie direkt die elektrische Ansteuerung (`u_q`, `i_q`), das Betriebsverhalten (`motor_speed`, `torque`) und dem thermischen Zustand (`pm`) des Motors verknüpfen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot with selected main features\n",
    "features_to_plot = ['u_q', 'i_q', 'motor_speed', 'torque', 'pm']\n",
    "sns.pairplot(exploration_set[features_to_plot], plot_kws={'alpha':0.2})\n",
    "plt.suptitle(\"Pairplot – Hauptmerkmale\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211be25",
   "metadata": {},
   "source": [
    "Die visualisierten Merkmale (`u_q`, `i_q`, `motor_speed`, `torque`, `pm`) zeigen wie erwartet die physikalischen Zusammenhänge:\n",
    "\n",
    "- **`i_q` und `torque`** korrelieren stark positiv, was die direkte Abhängigkeit des Drehmoments vom q-Achsen-Strom bestätigt.\n",
    "- **`motor_speed` vs. `torque`** zeigt eine typische inverse Beziehung bei konstantem Lastmoment – ein erwarteter Effekt aus dem stationären Betrieb.\n",
    "- **`u_q` hängt sowohl mit `i_q` als auch mit `motor_speed` zusammen**, da Spannung, Strom und Drehzahl über die Spannungsdifferenzgleichung verknüpft sind.\n",
    "\n",
    "Zusätzlich wurden die **Verteilungen und Boxplots der einzelnen Merkmale** separat nebeneinander dargestellt.  \n",
    "Dadurch lassen sich Schiefe, Ausreißer und Dichtebereiche der Messdaten untersuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47146e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_to_plot:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "    # Dsitribution\n",
    "    sns.histplot(exploration_set[col], kde=True, bins=50, ax=axes[0])\n",
    "    axes[0].set_title(f\"Verteilung: {col}\")\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(x=exploration_set[col], color='skyblue', fliersize=2, ax=axes[1])\n",
    "    axes[1].set_title(f\"Boxplot: {col}\")\n",
    "    axes[1].grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0f5dd",
   "metadata": {},
   "source": [
    "Auch in der Visulaliserung der Hauptmerkmale sind keine Ausreißer oder besondere Schieflagen zu erkennen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05539c80",
   "metadata": {},
   "source": [
    "#### Neue Attribut-Kombinationen\n",
    "\n",
    "Abgeleitet aus den obigen Erkenntnissen und zur Erweiterung der Merkmalsbasis wird zunächst die elektrische Leistung (`power`) als neue Variable berechnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91e67f-3e8e-4078-a336-883b7103ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power and store it in a new 'power' column and calculate the correlation matrix with all other attributes\n",
    "exploration_set[\"power\"] = exploration_set[\"u_d\"] * exploration_set[\"i_d\"] + exploration_set[\"u_q\"] * exploration_set[\"i_q\"]\n",
    "corr_matrix = exploration_set.corr()\n",
    "corr_matrix[\"power\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de19acc-2509-4918-95d4-4e68bee14419",
   "metadata": {},
   "source": [
    "Die starke positive Korrelation zu `torque` (0,75) und `i_q` (0,72) bestätigt physikalisch erwartete Zusammenhänge. Allerdings zeigt `power` nur eine schwache positive Korrelation mit der Zielgröße `pm` (0,18), was auf eine begrenzte Aussagekraft der Leistung als Prädiktor für die Magnettemperatur hinweist.\n",
    "Aufgrund dieser geringen Relevanz wird die Leistung als Feature für das Modell nicht weiter verfolgt.\n",
    "\n",
    "Im nächsten Schritt erfolgt eine Untersuchung der **Stromstärke (current magnitude)** als möglicher aussagekräftigerer Prädiktor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the current magnitude and store it in a new 'current_magnitude' column and calculate the correlation matrix with all other attributes\n",
    "exploration_set[\"current_magnitude\"] = np.sqrt(exploration_set[\"i_d\"]**2 + exploration_set[\"i_q\"]**2)\n",
    "corr_matrix = exploration_set.corr()\n",
    "corr_matrix[\"current_magnitude\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972848a5",
   "metadata": {},
   "source": [
    "Die Korrelationsanalyse zeigt positive Zusammenhänge mit `torque` und `motor_speed`. Die Korrelation mit der Zielvariable `pm` ist mit 0,25 aber nicht sehr hoch.\n",
    "\n",
    "Allerdings korreliert `current_magnitude` moderat positive mit den Temperaturen von Wicklung (`stator_winding`, 0,57) und Zahn (`stator_tooth`, 0,42), welche wiederum stark mit der Zielvariable korrelieren.\n",
    "\n",
    "Diese Ergebnisse deuten darauf hin, dass die Stromstärke ein relevanter Einflussfaktor für die Temperaturentwicklung im Motor sein könnte und somit als Feature in die Modellierung aufgenommen werden sollte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528482a",
   "metadata": {},
   "source": [
    "#### Daten Bereinigung\n",
    "\n",
    "Das untenstehende Diagramm zeigt die Verteilung von `motor_speed` im Intervall [-0.1, 0.1]. Es macht sichtbar, wie stark dieses Feature um den Nullpunkt konzentriert ist. Die Visualisierung soll die Auswahl eines sinnvollen Schwellenwerts (`interval`) für den `ZeroCloseValueFilter` Transformer unterstüzen.\n",
    "\n",
    "Ziel: Ggf. Zeilen mit 0-nahen Werten gezielt entfernen, um mögliche Verzerrungen im Modelltraining zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define interval\n",
    "x = 0.1\n",
    "\n",
    "# Filter data where motor_speed is in the interval [-x, +x]\n",
    "ud_near_zero = exploration_set.query(f\"abs(motor_speed) <= {x}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = sns.histplot(ud_near_zero[\"motor_speed\"], bins=100, kde=True, color=\"steelblue\")\n",
    "plt.title(f\"Verteilung von motor_speed im Interval [-{x}, +{x}]\")\n",
    "plt.xlabel(\"motor_speed\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61700233",
   "metadata": {},
   "source": [
    "#### Test: Entfernen 0-naher Messwerte aus dem Datensatz\n",
    "\n",
    "In diesem Schritt wird getestet, ob sich das Entfernen von Messwerten mit sehr kleinen Absolutwerten positiv auf die Performance der ML-Modelle auswirkt.  \n",
    "Der Filter wird testweise angewendet. Die zugehörigen Zielwerte (`pm`) werden dabei synchron mitgefiltert, um die Datenintegrität zu wahren.  \n",
    "Später kann untersucht werden, ob dieser Vorverarbeitungsschritt die Modellgüte verbessert oder nicht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41820fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all rows from the dataset where any of the key electrical features \n",
    "# (motor_speed, i_q, i_d, u_d, u_q) are within a near-zero interval around 0. \n",
    "# Define filter parameters\n",
    "cols_to_check = [\"motor_speed\", \"i_q\", \"i_d\", \"u_d\", \"u_q\"]\n",
    "interval = 0.01  # Value estimated from data exploration\n",
    "\n",
    "# Filter out rows where any of the selected features are near zero\n",
    "mask = (exploration_set[cols_to_check].abs() > interval).all(axis=1)\n",
    "\n",
    "# Apply mask to both features and labels\n",
    "motor_filtered = exploration_set[mask].reset_index(drop=True)\n",
    "\n",
    "# Print dataset size comparison\n",
    "print(\"Rows before filtering:\", len(exploration_set))\n",
    "print(\"Rows after filtering:\", len(motor_filtered))\n",
    "print(\"Rows removed:\", len(exploration_set) - len(motor_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782701d1",
   "metadata": {},
   "source": [
    "*__Nachtrag:__* Es zeigte sich, dass ein entfernen 0-naher Messwerte keinen erkennbaren Einfluss auf die Vorhersage-Performance hat. Deswegen wird dieser Schritt nicht weiter verfolgt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763ed61",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Daten Vorbereitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cb37b",
   "metadata": {},
   "source": [
    "\n",
    "Im nächsten Schritt wird eine  Kopie des Trainingsdatensatzes (`strat_train_set`) erzeugt, damit das Originaldataset unverändert bleit.\n",
    "Darauf aufbauend werden die Features vom Zielwert getrennt. Die Zielvariable `pm` wird als eigene Serie (`motor_pm_labels`) extrahiert, während die Trainingsdaten ohne `pm` als Eingabedaten (`motor`) verbleiben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da5268-5c9c-428b-9480-aa509ad0a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target labels by copying the 'pm' column\n",
    "motor_pm_labels = strat_train_set[\"pm\"].copy()\n",
    "\n",
    "# Prepare the feature set by dropping the target column 'pm' for training\n",
    "motor = strat_train_set.drop(\"pm\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcfded7",
   "metadata": {},
   "source": [
    "* Im Datensatz sind keine fehlenden Werte vorhanden, daher ist keine Datenimputation notwendig.  \n",
    "* Da alle Features numerisch sind, ist kein Encoding kategorialer Variablen erforderlich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7d924",
   "metadata": {},
   "source": [
    "#### Transformer\n",
    "\n",
    "Ziel ist die Vorhersage der Permanentmagnet-Temperatur (`pm`) auf Basis elektrischer Größen wie Spannung (`u_d`, `u_q`) und Strom (`i_d`, `i_q`) sowie mechanischer Größen wie Drehmoment und Drehzahl. Temperaturdaten benachbarter Bauteile sollen bewusst außen vor bleiben, da diese nicht in jeder Anwendung zwangsläufig zur Verfügung stehen. Das entfernen dieser Features kann jedoch als Hyperparameter `drop_selected_features` gesteuert werden.\n",
    "\n",
    "Die `profil_id` ist kein allgemeingültiger Parameter und soll nicht zur Schätzung der PM-Temperatur genutzt werden. Daher wird sie immer entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89285f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to drop selected features from the dataset\n",
    "# Always drop 'profile_id'\n",
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_temp_features=True):\n",
    "        self.drop_temp_features = drop_temp_features\n",
    "        self.features_to_drop = [\n",
    "            \"coolant\", \n",
    "            \"stator_winding\", \n",
    "            \"stator_tooth\", \n",
    "            \"stator_yoke\", \n",
    "            \"ambient\"\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting necessary\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Always drop 'profile_id'\n",
    "        X = X.drop(columns=[\"profile_id\"])\n",
    "        \n",
    "        # If dropping is disabled, return original data unchanged\n",
    "        if not self.drop_temp_features:\n",
    "            return X\n",
    "\n",
    "        # Drop specified columns if they exist\n",
    "        return X.drop(columns=[f for f in self.features_to_drop if f in X.columns])\n",
    "    \n",
    "# Instantiate transformer with dropping enabled for manual testing\n",
    "dropper = FeatureDropper(drop_temp_features=True)\n",
    "motor_reduced = dropper.transform(motor)\n",
    "\n",
    "motor_reduced.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c614edc-fd8f-472f-a011-0a1ca929ea55",
   "metadata": {},
   "source": [
    "Es soll das neue Feature `current_magnitude` aus den Voruntersuchungen ergänzt werden:\n",
    "Dazu wird ein Transformer der Klasse `CurrentMagnitudeAdder` implementiert, der als Teil der Datenvorverarbeitung die Stromstärke berechnet und als neue Spalte an den Datensatz anhängt.  \n",
    "Der Transformer enthält den Hyperparameter `add_current_magnitude`, mit dem gesteuert werden kann, ob das neue Feature current_magnitude hinzugefügt wird oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to add a new feature 'current_magnitude' to the dataset\n",
    "class CurrentMagnitudeAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_current_magnitude=True):\n",
    "        self.add_current_magnitude = add_current_magnitude\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting necessary\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # If feature addition is disabled, return original data unchanged\n",
    "        if not self.add_current_magnitude:\n",
    "            return X\n",
    "\n",
    "        # Calculate current magnitude as sqrt(i_d^2 + i_q^2) and add as new column\n",
    "        current_magnitude = np.sqrt(X[\"i_d\"]**2 + X[\"i_q\"]**2)\n",
    "        return X.assign(current_magnitude=current_magnitude)\n",
    "\n",
    "\n",
    "# Instantiate transformer with feature addition enabled for manual testing\n",
    "attr_adder = CurrentMagnitudeAdder(add_current_magnitude=True)\n",
    "motor_extra_attribs = attr_adder.transform(motor)\n",
    "motor_extra_attribs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a1680",
   "metadata": {},
   "source": [
    "#### Transformations Pipeline\n",
    "\n",
    "Da alle Features numerisch sind und sequenzeill abgearbeitet werden, genügt eine einfache Pipeline. Ein ColumnTransformer wäre nur nötig, wenn unterschiedliche Spalten unterschiedliche Vorverarbeitungen brauchen.\n",
    "\n",
    "Um Probleme aufgrund unterschiedlicher Größenordnungen der Features auszuschließen werden alle Daten am Ende der Pipeline standatisert skaliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b068f-053d-4f06-9aae-377723f3e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('feature_dropper', FeatureDropper()), # Drops profil_id & temperature features, estimation should not be based on other temperatures\n",
    "        ('magnitude_attrib_adder', CurrentMagnitudeAdder()), # Add custom feature 'current_magnitude'       \n",
    "        ('std_scaler', StandardScaler()), # Scale all Features based on std\n",
    "        ('regressor', None) # Placeholder\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pipeline on training data and apply transformations\n",
    "motor_prepared = pipeline.fit_transform(motor)\n",
    "\n",
    "# Display transformed feature matrix for verification\n",
    "motor_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba1620",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Modell-Training\n",
    "\n",
    "#### Untersuchte Modelle\n",
    "\n",
    "Neben dem `Random Forest` (nichtlinear, robust, bildlich vorstellbar) und einem neuronalen Netz `ANN` (leistungsstark, aber komplex) wird als drittes Modell eine `lineare Regression` gewählt.\n",
    "\n",
    "*Begründung:*\n",
    "Die lineare Regression dient als Baseline-Modell: Sie ist einfach, schnell trainiert und gut interpretierbar. So lässt sich nachvollziehen, ob komplexere Modelle wie ANN oder Random Forest tatsächlich einen Mehrwert bieten oder ob bereits eine lineare Beziehung ausreicht.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762fccf6",
   "metadata": {},
   "source": [
    "#### Modellbewertung mittels n-fold cross-validation\n",
    "\n",
    "Die Funktion `evaluate_model_crossFold` soll die objektive Evaluierung aller untersuchten Regressionsmodellen durch **n-fold cross-validation** ermöglichen. Dabei wird das Modell mehrfach auf unterschiedlichen Trainings- und Validierungssplits getestet, um Überanpassung zu vermeiden und die Verallgemeinerungsfähigkeit zuverlässig abzuschätzen.\n",
    "\n",
    "Die verwendete Bewertungsmetrik ist der **Root Mean Squared Error (RMSE)**, der die durchschnittliche Vorhersageabweichung quantifiziert und insbesondere größere Fehler stärker gewichtet. Die Funktion liefert neben den einzelnen RMSE-Werten der Folds auch deren Mittelwert und Standardabweichung zurück, um die Performance stabil und vergleichbar über verschiedene Modelle zu bewerten.\n",
    "\n",
    "Als zweite Bewertungsmetrik wird der **Mean Absolute Error (MAE)** verwendet um die tatsächliche Abweichung in °C einschätzen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb856b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_crossFold(model, training_features, training_labels, cv=5, display=False):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model using k-fold cross-validation (default: 5-fold).    \n",
    "    Computes both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
    "\n",
    "    Parameters:\n",
    "    - model: the regression model to evaluate\n",
    "    - training_features: preprocessed training features\n",
    "    - training_labels: training labels\n",
    "    - cv: number of cross-validation folds (default: 10)\n",
    "    - display: if True, prints scores and statistics\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with RMSE & MAE scores, mean, and standard deviation  \n",
    "    \"\"\"\n",
    "    \n",
    "    # RMSE\n",
    "    scores = cross_val_score(model, training_features, training_labels, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    " \n",
    "    \n",
    "    # MAE\n",
    "    neg_mae_scores = cross_val_score(model, training_features, training_labels, scoring=\"neg_mean_absolute_error\", cv=cv)\n",
    "    mae_scores = -neg_mae_scores\n",
    "\n",
    "    results = {\n",
    "        \"rmse_scores\": rmse_scores,\n",
    "        \"mean_rmse\": rmse_scores.mean(),\n",
    "        \"std_rmse\": rmse_scores.std(),\n",
    "        \"mae_scores\": mae_scores,\n",
    "        \"mean_mae\": mae_scores.mean(),\n",
    "        \"std_mae\": mae_scores.std()\n",
    "    }\n",
    "\n",
    "    if display:\n",
    "        print(\"RMSE scores:\", results[\"rmse_scores\"])\n",
    "        print(\"Mean RMSE  :\", results[\"mean_rmse\"])\n",
    "        print(\"Std RMSE   :\", results[\"std_rmse\"])\n",
    "        print(\"MAE scores  :\", results[\"mae_scores\"])\n",
    "        print(\"Mean MAE    :\", results[\"mean_mae\"])\n",
    "        print(\"Std MAE     :\", results[\"std_mae\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0dfb7",
   "metadata": {},
   "source": [
    "#### Modell 1: Lineare Regression als Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model on the preprocessed training data and target labels\n",
    "lin_reg.fit(motor_prepared, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be3dbf",
   "metadata": {},
   "source": [
    "Zur Kontrolle wird die vollständige Preprocessing-Pipeline auf einige wenige Trainingsdaten angewendet. Um ein erstes Gefühl für die Modellgüte zu bekommen, werden die vorhergesagten Werte (`Predictions`) werden den tatsächlichen Werten (`Actual Labels`) gegenübergestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the full preprocessing pipeline on a few training instances\n",
    "some_data = motor.iloc[:5]\n",
    "some_labels = motor_pm_labels.iloc[:5]\n",
    "\n",
    "# Apply the preprocessing pipeline\n",
    "some_data_prepared = pipeline.transform(some_data)\n",
    "\n",
    "# Make predictions and compare them to the actual labels\n",
    "print(\"Predictions   :\", np.round(lin_reg.predict(some_data_prepared),1))\n",
    "print(\"Actual Labels :\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c6189",
   "metadata": {},
   "source": [
    "Die Ergebnisse sehen auf den ersten Blick schon ganz gut aus. Im nächsten Schritt wird das trainierte lineare Regressionsmodell auf dem gesamten vorverarbeiteten Trainingsdatensatz angewendet und evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaef72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model performance\n",
    "lin_reg_predictions = lin_reg.predict(motor_prepared)\n",
    "lin_reg_rmse = np.sqrt(mean_squared_error(motor_pm_labels, lin_reg_predictions))\n",
    "print(\"Performance RMSE: \", lin_reg_rmse)\n",
    "\n",
    "# And cross-validate Model\n",
    "lin_reg_results = evaluate_model_crossFold(lin_reg, motor_prepared, motor_pm_labels, cv=5, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b48074",
   "metadata": {},
   "source": [
    "Die **lineare Regression** wird als einfaches, schnelles und gut interpretierbares Baseline-Modell eingesetzt. Sie erlaubt eine erste Einschätzung, ob die zu modellierende Zielgröße bereits durch lineare Zusammenhänge gut beschrieben werden kann.\n",
    "\n",
    "Die lineare Regression zeigt in der Kreuzvalidierung ein sehr stabiles Verhalten: Die RMSE-Werte liegen eng beieinander mit einem Mittelwert von 15.62 und einer minimalen Standardabweichung von 0.012. Der mittlere absolute Fehler liegt von der Größenordnung bereits in der Nähe der Ziel-Toleranz. \n",
    "\n",
    "Das Modell wird gemeinsam mit seinen Hyperparametern und CV-Ergebnissen gespeichert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77575e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle everything in one object\n",
    "lin_reg_model_package = {\n",
    "    \"model\": lin_reg,\n",
    "    \"hyperparams\": lin_reg.get_params(),\n",
    "    \"cv_results\": lin_reg_results\n",
    "}\n",
    "\n",
    "# save Model\n",
    "joblib.dump(lin_reg_model_package, \"models/lin_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fe770",
   "metadata": {},
   "source": [
    "Die Funktion `load_model_package()` wird momentan noch nicht verwendet, kann aber ggf. später zum laden der gespeicherten Modelle wichtig werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0de197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load a saved model package containing the trained model,\n",
    "# its hyperparameters, cross-validation scores and predictions.\n",
    "def load_model_package(model_path):\n",
    "    \"\"\"\n",
    "    Loads a previously saved model package (.pkl file), which contains:\n",
    "    - the trained model,\n",
    "    - hyperparameters,\n",
    "    - cross-validation results,\n",
    "    - predictions on training data.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to the saved .pkl file\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with keys:\n",
    "        - \"model\": the trained model (e.g., RandomForestRegressor)\n",
    "        - \"hyperparams\": hyperparameters used during training\n",
    "        - \"cv_results\": cross-validation scores\n",
    "\n",
    "    Example usage:\n",
    "    ----------------\n",
    "    package = load_model_package(\"models/forest_reg.pkl\")\n",
    "    model = package[\"model\"]\n",
    "    params = package[\"hyperparams\"]\n",
    "    scores = package[\"cv_results\"]\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model package not found at: {model_path}\")\n",
    "\n",
    "    loaded_package = joblib.load(model_path)\n",
    "    return loaded_package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ac26e",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "\n",
    "**ALLE** estimators und cv anpassen\n",
    "\n",
    "**WERTE** in allen folgenden Markdown prüfen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6c62b",
   "metadata": {},
   "source": [
    "#### Modell 2: Random Forest (Target Methode)\n",
    "\n",
    "**Random Forest** ist ein leistungsstarkes, nichtlineares Ensemblemodell, das aus vielen Entscheidungsbäumen besteht. Jeder Baum lernt auf einer zufälligen Teilmenge der Daten und trifft eine eigene Vorhersage – das endgültige Ergebnis ist der Durchschnitt aller Bäume. Dadurch ist das Modell robust gegenüber Ausreißern und Überanpassung und kann auch komplexe, nichtlineare Zusammenhänge gut abbilden.\n",
    "\n",
    "Der Parameter `n_estimators` wurde bewusst etwas kleiner gewählt, um die Rechenzeit zu begrenzen. Die gewählte Einstellung stellt somit einen Kompromiss zwischen Modellgüte und Effizienz dar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e133c88",
   "metadata": {},
   "source": [
    "1. Modell initalisieren & trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Random Forest Regressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model on the preprocessed training data and target labels\n",
    "forest_reg.fit(motor_prepared, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8882ce",
   "metadata": {},
   "source": [
    "2. Modell evaluieren &\n",
    "3. Modell Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model performance\n",
    "forest_predictions = forest_reg.predict(motor_prepared)\n",
    "forest_reg_rmse = np.sqrt(mean_squared_error(motor_pm_labels, forest_predictions))\n",
    "print(\"Performance RMSE: \", forest_reg_rmse)\n",
    "\n",
    "# cross-validate Model\n",
    "forest_reg_results = evaluate_model_crossFold(forest_reg, motor_prepared, motor_pm_labels, cv=5, display=True)\n",
    "\n",
    "\n",
    "# Bundle everything in one object\n",
    "forest_reg_model_package = {\n",
    "    \"model\": forest_reg,\n",
    "    \"hyperparams\": forest_reg.get_params(),\n",
    "    \"cv_results\": forest_reg_results\n",
    "}\n",
    "\n",
    "# save Model\n",
    "joblib.dump(forest_reg_model_package, \"models/forest_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d52117",
   "metadata": {},
   "source": [
    "Das Random-Forest-Modell erzielt mit einem RMSE von **3.06** auf dem Gesamtdatensatz eine deutlich bessere Vorhersagegenauigkeit als die lineare Regression (RMSE = 15.6). Auch in der Kreuzvalidierung bleibt die Modellgüte mit einem durchschnittlichen RMSE von **6.12** und einem MAE von **3.04** klar überlegen.\n",
    "\n",
    "Allerdings ist die Differenz zwischen Trainings- und Validierungsfehler auffällig groß – ein Hinweis auf **Overfitting**: Das Modell passt sich stark an die Trainingsdaten an, verliert aber an Generalisierungsfähigkeit. Mögliche Gegenmaßnahmen wären eine Reduktion der Modellkomplexität, Regularisierung oder die Verwendung eines größeren Trainingsdatensatzes.\n",
    "\n",
    "Vor dem Feintuning wird ein Neuronales-Netz (`ANN`) getestet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c7ad9",
   "metadata": {},
   "source": [
    "#### Modell 3: Artificial Neural Network (ANN)\n",
    "\n",
    "**Künstliche neuronale Netze (ANN)** sind von der Struktur biologischer Nervensysteme inspiriert und bestehen aus mehreren Schichten miteinander verbundener künstlicher Neuronen. Sie sind in der Lage, hochkomplexe und nichtlineare Zusammenhänge in den Daten zu erfassen und liefern oft sehr gute Ergebnisse bei ausreichend großen und vielfältigen Datensätzen. ANNs sind allerdings rechenintensiv, benötigen sorgfältige Hyperparameterabstimmung und sind in ihrer Struktur schwer interpretierbar.\n",
    "\n",
    "Der Parameter `hidden_layer_size` wurde bewusst etwas kleiner gewählt, um die Rechenzeit zu begrenzen. Einstellung stellt somit einen Kompromiss zwischen Modellgüte und Effizienz dar.\n",
    "\n",
    "1. Modell initalisieren & trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an Artificial Neural Network (ANN) Regressor\n",
    "ann_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,),  # one hidden layer with 10 Neuronen\n",
    "    solver='adam',\n",
    "    max_iter=600,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the preprocessed training data and target labels\n",
    "ann_reg.fit(motor_prepared, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120df6d",
   "metadata": {},
   "source": [
    "2. Modell evaluieren &\n",
    "3. Modell Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance\n",
    "ann_predictions = ann_reg.predict(motor_prepared)\n",
    "ann_rmse = np.sqrt(mean_squared_error(motor_pm_labels, ann_predictions))\n",
    "print(\"Performance RMSE: \", ann_rmse)\n",
    "\n",
    "# Cross-validate the ANN model\n",
    "ann_results = evaluate_model_crossFold(ann_reg, motor_prepared, motor_pm_labels, cv=5, display=True)\n",
    "\n",
    "# Bundle everything in one object\n",
    "ann_model_package = {\n",
    "    \"model\": ann_reg,\n",
    "    \"hyperparams\": ann_reg.get_params(),\n",
    "    \"cv_results\": ann_results\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(ann_model_package, \"models/ann_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0b3ea",
   "metadata": {},
   "source": [
    "Das ANN erzielt eine mittlere RMSE von etwa **13,43** und eine mittlere absolute Abweichung (MAE) von ca. **10,24**. Während des Trainings wird die Warnung ausgegeben, dass die maximale Anzahl von 500 Iterationen erreicht wurde, ohne dass der Optimierer konvergierte. Dies deutet darauf hin, dass das Modell nicht vollständig trainiert wurde und die Leistung noch verbessert werden könnte, wenn mehr Rechenressourcen zur Verfügung stünde.\n",
    "\n",
    "Trotz dieser Limitierung schneidet das ANN besser ab als die lineare Regression, die mit einer mittleren RMSE von ca. **15,62** und einer MAE von etwa **12,92** etwas schlechtere Vorhersagen liefert.\n",
    "\n",
    "Im Vergleich dazu übertrifft der Random Forest beide Modelle deutlich mit einer mittleren RMSE von ca. **6,12** und einer MAE von etwa **3,04**. Dies zeigt, dass der Random Forest komplexe Zusammenhänge im Datensatz wesentlich besser abbilden kann und insgesamt die beste Vorhersagegenauigkeit erreicht.\n",
    "\n",
    "Fazit:\n",
    "- Das ANN liefert trotz Trainingsbegrenzung bessere Ergebnisse als die lineare Regression.  \n",
    "- Die Warnung zur nicht erfolgten Konvergenz schränkt die Aussagekraft der ANN-Ergebnisse ein und signalisiert Optimierungspotenzial.  \n",
    "- Der Random Forest ist dem ANN und der linearen Regression hinsichtlich Genauigkeit und Stabilität klar überlegen und stellt damit das am besten geeignete Modell für diesen Anwendungsfall dar.\n",
    "\n",
    "#### Zusammenfassung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46257e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the summarized values\n",
    "summary = {\n",
    "    \"Linear Regression\": {\n",
    "        \"RMSE (mean ± std)\": f\"{lin_reg_results['mean_rmse']:.3f} ± {lin_reg_results['std_rmse']:.3f}\",\n",
    "        \"MAE (mean ± std)\": f\"{lin_reg_results['mean_mae']:.3f} ± {lin_reg_results['std_mae']:.3f}\",\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"RMSE (mean ± std)\": f\"{forest_reg_results['mean_rmse']:.3f} ± {forest_reg_results['std_rmse']:.3f}\",\n",
    "        \"MAE (mean ± std)\": f\"{forest_reg_results['mean_mae']:.3f} ± {forest_reg_results['std_mae']:.3f}\",\n",
    "    },\n",
    "    \"ANN\": {\n",
    "        \"RMSE (mean ± std)\": f\"{ann_results['mean_rmse']:.3f} ± {ann_results['std_rmse']:.3f}\",\n",
    "        \"MAE (mean ± std)\": f\"{ann_results['mean_mae']:.3f} ± {ann_results['std_mae']:.3f}\",\n",
    "    }\n",
    "}\n",
    "\n",
    "results_pre = pd.DataFrame.from_dict(summary, orient='index')\n",
    "display(results_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19167f2b",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "gesammt zusammenfasung Tabelle machen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d51e2",
   "metadata": {},
   "source": [
    "#### Analyse der wichtigsten Features\n",
    "\n",
    "Aus dem ursprünglichen Datensatz wurden weniger relevante Merkmale entfernt. Ergänzt wurde `current_magnitude` als abgeleiteter Gesamtstrom aus `i_d` und `i_q`.\n",
    "Daher muss zur Analyse der wichtigste Features zunächst die endgültige Feature-Liste erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = list(motor.columns)\n",
    "dropped_features = ['profile_id', 'stator_yoke', 'stator_tooth', 'stator_winding', 'coolant', 'ambient']\n",
    "remaining_features = [f for f in original_features if f not in dropped_features]\n",
    "\n",
    "final_features = remaining_features + ['current_magnitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f28af5",
   "metadata": {},
   "source": [
    "Diese wird dann genutzt um die Wichtigkeit der jeweiligen Features für die lineare Regression zu labeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance = absolute value of coefficients\n",
    "feature_importance_lin = pd.Series(\n",
    "    np.abs(lin_reg.coef_), \n",
    "    index=final_features\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Lineare Regression – wichtigste Features:\")\n",
    "print(feature_importance_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f42ffe",
   "metadata": {},
   "source": [
    "Ebenso für das Random Forest Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d634bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance direkt aus dem Modell\n",
    "feature_importance_rf = pd.Series(\n",
    "    forest_reg.feature_importances_, \n",
    "    index=final_features\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest – wichtigste Features:\")\n",
    "print(feature_importance_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325f8e4",
   "metadata": {},
   "source": [
    "Und das neuronale Netz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Permutation importance: langsam, aber für ANN notwendig\n",
    "result = permutation_importance(\n",
    "    ann_reg, motor_prepared, motor_pm_labels, \n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "feature_importance_ann = pd.Series(\n",
    "    result.importances_mean,\n",
    "    index=final_features\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"ANN – wichtigste Features (Permutation Importance):\")\n",
    "print(feature_importance_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818c293",
   "metadata": {},
   "source": [
    "Werden alle Ergebnisse normiert und nach der Target Methode (RF) sortiert dargestellt ergibt sich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    \"LinearRegression\": feature_importance_lin,\n",
    "    \"RandomForest\": feature_importance_rf,\n",
    "    \"ANN\": feature_importance_ann\n",
    "})\n",
    "\n",
    "# normalized to same scale\n",
    "importance_df = importance_df / importance_df.max()\n",
    "\n",
    "# Comparison of feature importance\n",
    "print(\"Die normierte Feature-Relevanz: \")\n",
    "importance_df.sort_values(\"RandomForest\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233f19e",
   "metadata": {},
   "source": [
    "Die normierte Feature-Relevanz tance zeigt deutliche Unterschiede in der Gewichtung der Eingangsgrößen je nach Modelltyp:\n",
    "\n",
    "- **`motor_speed`** ist für alle Modelle das wichtigste Merkmal.\n",
    "- **`i_q`** dominiert im ANN-Modell, was auf die nichtlineare Beziehung zum Drehmoment hinweist, die das neuronale Netz besser erfassen kann.\n",
    "- **`u_d` und `u_q`** werden vom Random Forest deutlich stärker gewichtet als vom ANN – ein Hinweis auf mögliche Interaktionseffekte oder Entscheidungsgrenzen, die baumbasierte Modelle besser abbilden.\n",
    "- Die **Lineare Regression** gewichtet `u_q`, `i_d` und `i_q` moderat, erkennt jedoch kaum nichtlineare Zusammenhänge (`torque` hat dort z. B. wenig Einfluss).\n",
    "\n",
    "Das abgeleitete Feature **`current_magnitude`** zeigt in keinem der Modelle eine dominante Bedeutung.  \n",
    "Obwohl es den Gesamtstrom beschreibt, scheint der getrennte Informationsgehalt von `i_d` und `i_q` für die Modelle wertvoller zu sein.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa816826",
   "metadata": {},
   "source": [
    "#### Analyse der Fehlertypen\n",
    "\n",
    "Zur Bewertung der Modellgüte wird eine kombinierte Visualisierung verwendet:\n",
    "\n",
    "- **Links:** Ein Scatterplot vergleicht die vorhergesagten Werte mit den tatsächlichen Ist-Werten.  \n",
    "  Eine ideale Modellvorhersage würde sich entlang der roten Diagonalen befinden – Abweichungen davon zeigen systematische Fehler oder Streuung.\n",
    "\n",
    "- **Rechts:** Das Histogramm der Residuen (`y_true - y_pred`) zeigt die Verteilung der Vorhersagefehler.  \n",
    "  Eine symmetrische, glockenförmige Verteilung mit Mittelwert nahe 0 deutet auf ein gut kalibriertes Modell hin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571448b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to analyze the types of errors the models make\n",
    "def plot_model_diagnostics(y_true, y_pred, model_name):\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Scatterplot: Prediction vs. actual value\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.4, ax=axes[0])\n",
    "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r', linewidth=2)\n",
    "    axes[0].set_xlabel(\"Ist-Wert (y_true)\")\n",
    "    axes[0].set_ylabel(\"Vorhersage (y_pred)\")\n",
    "    axes[0].set_title(f\"{model_name} – Vorhersage vs. Ist-Wert\")\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Histogram of the residuals\n",
    "    sns.histplot(residuals, kde=True, bins=30, color='orange', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Residuum (y_true - y_pred)\")\n",
    "    axes[1].set_title(f\"{model_name} – Verteilung der Residuen\")\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot analysis for all 3 models\n",
    "plot_model_diagnostics(motor_pm_labels, lin_reg_predictions, \"Lineare Regression\")\n",
    "\n",
    "plot_model_diagnostics(motor_pm_labels, forest_predictions, \"Random Forest\")\n",
    "\n",
    "plot_model_diagnostics(motor_pm_labels, ann_predictions, \"ANN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244bced",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "Schlussfolgerung\n",
    "Ziel: Herausfinden, wo dein Modell Schwächen hat – z. B. bei Randwerten, Ausreißern oder bestimmten Bedingungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ba28f",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Feintuning der Modelle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f39105",
   "metadata": {},
   "source": [
    "#### Hyperparameter-Tuning\n",
    "\n",
    "Zur effizienten Optimierung der Modellparameter wird ein zweistufiges Verfahren verwendet um für alle drei Modelle die besten Parameter zu finden.\n",
    "\n",
    "1. **RandomizedSearchCV**  \n",
    "   → Grobe Erkundung des Hyperparameterraums bei geringem Rechenaufwand  \n",
    "\n",
    "2. **GridSearchCV (optional)**  \n",
    "   → Feintuning auf Basis der vielversprechendsten Parameterbereiche aus Schritt 1  \n",
    "   → Zielgerichtete Optimierung mit eng gesetztem Parameter-Grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb38b3",
   "metadata": {},
   "source": [
    "#### Modell 1: Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98232d3a",
   "metadata": {},
   "source": [
    "Bei der linearen Regression wird nur der Hyperparameter `add_current_magnitude` überprüft. Ein **RandomizedSearchCV** ist daher hier noch nicht notwendig/sinvoll. Stattdessen wird direkt mit einem **GridSearchCV** nach dem besten Parameter-Wert gesucht.\n",
    "\n",
    "Unabhängig davon werden die **Temperaturmerkmale immer entfernt**, da die Zielsetzung explizit vorsieht, ein Modell ohne temperaturabhängige Eingangsdaten zu entwickeln.\n",
    "\n",
    "Bezüglich der **Feature-Engineering-Komponente `current_magnitude`** zeigte die Analyse der Feature-Relevanz keine eindeutige Tendenz. Daher wird der Nutzen im Rahmen des Hyperparameter-Tunings explizit getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87333183",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regressor\": [LinearRegression()],\n",
    "    \"magnitude_attrib_adder__add_current_magnitude\": [True, False], # Try prediction with and without the extra Feature\n",
    "}\n",
    "\n",
    "lin_reg_grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=2,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "lin_reg_grid_search.fit(motor, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9d2f3",
   "metadata": {},
   "source": [
    "Dies ergibt **A × B × C = D Modellkonfigurationen**, die jeweils mit XXX-facher Cross-Validation bewertet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b00831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utility function to print the best parameters and corresponding RMSE from a fitted GridSearchCV or RandomizedSearchCV object\n",
    "def print_search_summary(search_cv):\n",
    "    \"\"\"\n",
    "    Prints the best parameter combination and corresponding RMSE \n",
    "    from a fitted GridSearchCV or RandomizedSearchCV object.\n",
    "    \n",
    "    Parameters:\n",
    "        search_cv: A fitted instance of sklearn.model_selection.GridSearchCV \n",
    "                   or sklearn.model_selection.RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    print(\"\\nBeste Parameterkombination:\")\n",
    "    for key, value in search_cv.best_params_.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    # Calculate and print best RMSE from best_score_ (which is negative MSE)\n",
    "    best_rmse = np.sqrt(-search_cv.best_score_)\n",
    "    print(f\"\\nBester RMSE (basierend auf Cross-Validation): {best_rmse:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        \"best_params\": search_cv.best_params_,\n",
    "        \"best_rmse\": best_rmse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tuned_lin_reg = print_search_summary(lin_reg_grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea85af",
   "metadata": {},
   "source": [
    "Die Lineare Regression kommt also **mit** dem Feature `current_magnitude` auf etwas bessere Vorhersagen (RMSE: 15,73 zu 15,63)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e1c1e",
   "metadata": {},
   "source": [
    "#### Modell 2: Random Forest (Target Methode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfac6c",
   "metadata": {},
   "source": [
    "Im ersten Schritt kommt `RandomizedSearchCV` zum Einsatz. Dabei werden zufällig ausgewählte Kombinationen \n",
    "von Hyperparametern getestet – bei geringem Rechenaufwand. Dieser Ansatz ist besonders effizient, \n",
    "wenn nur eine  begrenzt Anzahl Modelltrainings durchführen kann/soll.\n",
    "\n",
    "Parameter:\n",
    "\n",
    " - `n_estimators`: Anzahl der Entscheidungsbäume\n",
    " - `max_features`: Anzahl der Features, die für jeden Split berücksichtigt werden\n",
    " - `n_iter`: Anzahl zufällige Kombinationen aus dem Parameterraum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"regressor\": [RandomForestRegressor(random_state=42)],\n",
    "    \"regressor__n_estimators\": randint(low=1, high=10),\n",
    "    \"regressor__max_features\": randint(low=1, high=7),  # 1 to all Features\n",
    "}\n",
    "\n",
    "forest_rnd_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distribs,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=42,\n",
    ")\n",
    "forest_rnd_search.fit(motor, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_tuned_forest = print_search_summary(forest_rnd_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dd572",
   "metadata": {},
   "source": [
    "Auf Basis der Ergebnisse mit **RandomizedSearchCV** wird nun ein eingeschränkter, sinnvoller Parameterbereich definiert, der gezielt mit **GridSearchCV** für jedes Modell durchgetestet wird. Anstelle von zufälligen Parameter-werten, werden jetzt also spezifische Kombinationen getestet.\n",
    "\n",
    "Unabhängig davon werden die **Temperaturmerkmale immer entfernt**, da die Zielsetzung explizit vorsieht, ein Modell ohne temperaturabhängige Eingangsdaten zu entwickeln.\n",
    "\n",
    "Bezüglich der **Feature-Engineering-Komponente `current_magnitude`** zeigte die Analyse der Feature-Relevanz keine eindeutige Tendenz. Daher wird der Nutzen im Rahmen des Hyperparameter-Tunings explizit getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regressor\": [RandomForestRegressor(random_state=42)],\n",
    "    \"regressor__n_estimators\": [1, 2],\n",
    "    \"regressor__max_features\": [1, 3, 7],\n",
    "    \"magnitude_attrib_adder__add_current_magnitude\": [True, False],\n",
    "}\n",
    "\n",
    "forest_grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "forest_grid_search.fit(motor, motor_pm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153ca20",
   "metadata": {},
   "source": [
    "Dies ergibt **A × B × C = D Modellkonfigurationen**, die jeweils mit XXX-facher Cross-Validation bewertet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tuned_forest = print_search_summary(forest_grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2eff09",
   "metadata": {},
   "source": [
    "#### Modell 3: Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e7d2",
   "metadata": {},
   "source": [
    "Analog zu den vorherigen Modellen folgt nun das hyperparametertuning des neuronalen Netzes. \n",
    "\n",
    "Parameter:\n",
    "\n",
    " - `hidden_layer_sizes`: Definiert die Struktur des Netzes (Neuronen, Schichten)\n",
    " - `alpha`: L2 Regularisierungsparameter. Beeinflusst Over-/Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"regressor\": [MLPRegressor(random_state=42, max_iter=600)],\n",
    "    \"regressor__hidden_layer_sizes\": [(5,), (10,), (20,), (50,), (100,)],\n",
    "    \"regressor__alpha\": uniform(0.001, 0.01)\n",
    "}\n",
    "\n",
    "ann_rnd_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distribs,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=42,\n",
    ")\n",
    "ann_rnd_search.fit(motor, motor_pm_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82402d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_tuned_ann = print_search_summary(ann_rnd_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1dc86a",
   "metadata": {},
   "source": [
    "Auf Basis der Ergebnisse mit **RandomizedSearchCV** wird nun ein eingeschränkter, sinnvoller Parameterbereich definiert, der gezielt mit **GridSearchCV** für jedes Modell durchgetestet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regressor\": [MLPRegressor(random_state=42, max_iter=600)],\n",
    "    \"regressor__hidden_layer_sizes\": [(10,), (20,)],\n",
    "    \"regressor__alpha\": [0.0001, 0.001],  # Regularization\n",
    "    \"magnitude_attrib_adder__add_current_magnitude\": [True, False],\n",
    "}\n",
    "\n",
    "ann_grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "ann_grid_search.fit(motor, motor_pm_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175437a",
   "metadata": {},
   "source": [
    "Dies ergibt **A × B × C = D Modellkonfigurationen**, die jeweils mit XXX-facher Cross-Validation bewertet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a16c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tuned_ann = print_search_summary(ann_grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91f2b6",
   "metadata": {},
   "source": [
    "#### Modell Vergleich\n",
    "\n",
    "Nach dem Feintuning der drei Modelle ergeben sich die folgenden RMSE-Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "def format_params(params):\n",
    "    return pprint.pformat(params, compact=True)\n",
    "\n",
    "# Dictionary with the summarized values\n",
    "summary = {\n",
    "    \"Linear Regression\": {\n",
    "        \"Best RMSE\": grid_tuned_lin_reg[\"best_rmse\"],\n",
    "        \"Best Params\": grid_tuned_lin_reg[\"best_params\"],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"Best RMSE\": grid_tuned_forest[\"best_rmse\"],\n",
    "        \"Best Params\": grid_tuned_forest[\"best_params\"],\n",
    "    },\n",
    "    \"ANN\": {\n",
    "        \"Best RMSE\": grid_tuned_ann[\"best_rmse\"],\n",
    "        \"Best Params\": grid_tuned_ann[\"best_params\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "results_post = pd.DataFrame.from_dict(summary, orient='index')\n",
    "display(results_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efba31",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "\n",
    "Zusammenfassung tabelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264f888",
   "metadata": {},
   "source": [
    "#### Modellwahl und finale Evaluation\n",
    "\n",
    "Das Modell **XXX** zeigt mit YYY die besten Ergebnisse mit der geringsten Fehlerquote und stabileren Vorhersagen im Vergleich zu den Alternativen.\n",
    "\n",
    "Zur Abschätzung des Generalisierungsfehlers wird das finale Modell abschließend auf dem separaten Testdatensatz evaluiert. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = forest_grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"pm\", axis=1)\n",
    "y_test = strat_test_set[\"pm\"].copy()\n",
    "\n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_predictions)\n",
    "\n",
    "print(f\"Finaler RMSE: {final_rmse:.3f}\")\n",
    "print(f\"Finaler MAE:  {final_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb01b2",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "Schlussfolgerung\n",
    "\n",
    "Ein einzelner Fehlerwert (MAE oder RMSE) reicht oft nicht aus, um eine fundierte Entscheidung über den Einsatz eines neuen Modells zu treffen. Um die Aussagekraft der Fehlerkennzahl besser einschätzen zu können, wird zusätzlich das **95% Konfidenzintervall** berechnet.  \n",
    "Es ibt an, in welchem Bereich der wahre Generalisierungsfehler mit hoher Wahrscheinlichkeit liegt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34b828",
   "metadata": {},
   "source": [
    "Das 95% Konfidenzintervall für den RMSE gibt den Wertebereich an, in dem der wahre RMSE mit 95%iger Sicherheit liegt. Es berücksichtigt die Stichprobenvarianz und zeigt die Präzision der RMSE-Schätzung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b171f1c",
   "metadata": {},
   "source": [
    "# <span style=\"color: RED;\">TODO</span>\n",
    "Schlussfolgerung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247740c",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: RED;\">TODO</span>\n",
    "### 7. Abschließende Zusammenfassung\n",
    "\n",
    "1. Document what you have done.\n",
    "    - write a summary of the results in a new, final section\n",
    "    - explain why your solution achieves the task objective\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
